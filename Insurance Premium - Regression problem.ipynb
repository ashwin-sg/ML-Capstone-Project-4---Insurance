{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%config IPCompleter.greedy=True\n",
    "\n",
    "insurance = pd.read_csv(\"Insurance data.csv\")\n",
    "# insurance.to_csv(\"Insurance data.csv\")\n",
    "\n",
    "insurance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Rows     : \" , insurance.shape[0])\n",
    "print (\"Columns  : \" , insurance.shape[1])\n",
    "print (\"\\nFeatures : \\n\" , insurance.columns.tolist())\n",
    "print (\"\\nMissing values :  \", insurance.isnull().sum().values.sum())\n",
    "print (\"\\nUnique values :  \\n\",insurance.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data exploration\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 10))\n",
    "insurance.plot(kind=\"hist\", y=\"age\", bins=70, color=\"b\", ax=axes[0][0])\n",
    "insurance.plot(kind=\"hist\", y=\"bmi\", bins=100, color=\"r\", ax=axes[0][1])\n",
    "insurance.plot(kind=\"hist\", y=\"children\", bins=6, color=\"g\", ax=axes[1][0])\n",
    "insurance.plot(kind=\"hist\", y=\"charges\", bins=100, color=\"orange\", ax=axes[1][1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 5))\n",
    "insurance.plot(kind='scatter', x='age', y='charges', alpha=0.5, color='green', ax=axes[0], title=\"Age vs. Charges\")\n",
    "insurance.plot(kind='scatter', x='bmi', y='charges', alpha=0.5, color='red', ax=axes[1], title=\"Bmi vs. Charges\")\n",
    "insurance.plot(kind='scatter', x='children', y='charges', alpha=0.5, color='blue', ax=axes[2], title=\"Children vs. Charges\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pal = [\"#FA5858\", \"#58D3F7\"]\n",
    "sns.scatterplot(x=\"children\", y=\"charges\", data=insurance, palette=pal, hue='smoker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"ticks\")\n",
    "pal = [\"#FA5858\", \"#58D3F7\"]\n",
    "\n",
    "sns.pairplot(insurance, hue=\"smoker\", palette=pal)\n",
    "plt.title(\"Smokers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance['region'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance.region.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance.drop([\"Unnamed: 0\"], axis=1, inplace=True) \n",
    "insurance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label or integer encoding is possible \n",
    "\n",
    "#insurance['sex'] = insurance['sex'].map(lambda s :1  if s == 'female' else 0)\n",
    "#insurance['smoker'] = insurance['smoker'].map(lambda s :1  if s == 'yes' else 0)\n",
    "\n",
    "#insurance.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding\n",
    "\n",
    "cat_col=['smoker','region','sex']\n",
    "num_col=[i for i in insurance.columns if i not in cat_col]\n",
    "num_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot=pd.get_dummies(insurance[cat_col])\n",
    "insurance=pd.concat([insurance[num_col],one_hot],axis=1)\n",
    "insurance.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = insurance.drop(['charges'], axis = 1)\n",
    "y = insurance.charges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalising the data is also an option\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression  # Import Linear Regression model\n",
    "\n",
    "multiple_linear_reg = LinearRegression(fit_intercept=False)  # Create a instance for Linear Regression model\n",
    "multiple_linear_reg.fit(X_train, y_train)  # Fit data to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "polynomial_features = PolynomialFeatures(degree=3)  # Create a PolynomialFeatures instance in degree 3\n",
    "x_train_poly = polynomial_features.fit_transform(X_train)  # Fit and transform the training data to polynomial\n",
    "x_test_poly = polynomial_features.fit_transform(X_test)  # Fit and transform the testing data to polynomial\n",
    "\n",
    "polynomial_reg = LinearRegression(fit_intercept=False)  # Create a instance for Linear Regression model\n",
    "polynomial_reg.fit(x_train_poly, y_train)  # Fit data to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_poly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor  # Import Decision Tree Regression model\n",
    "\n",
    "decision_tree_reg = DecisionTreeRegressor(max_depth=5, random_state=13)  # Create a instance for Decision Tree Regression model\n",
    "decision_tree_reg.fit(X_train, y_train)  # Fit data to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor  # Import Random Forest Regression model\n",
    "\n",
    "random_forest_reg = RandomForestRegressor(n_estimators=400, max_depth=5, random_state=13)  # Create a instance for Random Forest Regression model\n",
    "random_forest_reg.fit(X_train, y_train)  # Fit data to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR  # Import SVR model\n",
    "\n",
    "support_vector_reg = SVR(gamma=\"auto\", kernel=\"linear\", C=1000)  # Create a instance for Support Vector Regression model\n",
    "support_vector_reg.fit(X_train, y_train)  # Fit data to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing evaluation metrics\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict  # For K-Fold Cross Validation\n",
    "from sklearn.metrics import r2_score  # For find accuracy with R2 Score\n",
    "from sklearn.metrics import mean_squared_error  # For MSE\n",
    "from math import sqrt  # For squareroot operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction with training dataset:\n",
    "y_pred_MLR_train = multiple_linear_reg.predict(X_train)\n",
    "\n",
    "# Prediction with testing dataset:\n",
    "y_pred_MLR_test = multiple_linear_reg.predict(X_test)\n",
    "\n",
    "# Find training accuracy for this model:\n",
    "accuracy_MLR_train = r2_score(y_train, y_pred_MLR_train)\n",
    "print(\"Training Accuracy for Multiple Linear Regression Model: \", accuracy_MLR_train)\n",
    "\n",
    "# Find testing accuracy for this model:\n",
    "accuracy_MLR_test = r2_score(y_test, y_pred_MLR_test)\n",
    "print(\"Training Accuracy for Multiple Linear Regression Model: \", accuracy_MLR_train)\n",
    "\n",
    "# Find RMSE for training data:\n",
    "RMSE_MLR_train = sqrt(mean_squared_error(y_train, y_pred_MLR_train))\n",
    "print(\"RMSE for Training Data: \", RMSE_MLR_train)\n",
    "\n",
    "# Find RMSE for testing data:\n",
    "RMSE_MLR_test = sqrt(mean_squared_error(y_test, y_pred_MLR_test))\n",
    "print(\"RMSE for Testing Data: \", RMSE_MLR_test)\n",
    "\n",
    "# Prediction with 10-Fold Cross Validation:\n",
    "y_pred_cv_MLR = cross_val_predict(multiple_linear_reg, X, y, cv=10)\n",
    "\n",
    "# Find accuracy after 10-Fold Cross Validation\n",
    "accuracy_cv_MLR = r2_score(y, y_pred_cv_MLR)\n",
    "print(\"Accuracy for 10-Fold Cross Predicted Multiple Linaer Regression Model: \", accuracy_cv_MLR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction with training dataset:\n",
    "y_pred_PR_train = polynomial_reg.predict(x_train_poly)\n",
    "\n",
    "# Prediction with testing dataset:\n",
    "y_pred_PR_test = polynomial_reg.predict(x_test_poly)\n",
    "\n",
    "# Find training accuracy for this model:\n",
    "accuracy_PR_train = r2_score(y_train, y_pred_PR_train)\n",
    "print(\"Training Accuracy for Polynomial Regression Model: \", accuracy_PR_train)\n",
    "\n",
    "# Find testing accuracy for this model:\n",
    "accuracy_PR_test = r2_score(y_test, y_pred_PR_test)\n",
    "print(\"Testing Accuracy for Polynomial Regression Model: \", accuracy_PR_test)\n",
    "\n",
    "# Find RMSE for training data:\n",
    "RMSE_PR_train = sqrt(mean_squared_error(y_train, y_pred_PR_train))\n",
    "print(\"RMSE for Training Data: \", RMSE_PR_train)\n",
    "\n",
    "# Find RMSE for testing data:\n",
    "RMSE_PR_test = sqrt(mean_squared_error(y_test, y_pred_PR_test))\n",
    "print(\"RMSE for Testing Data: \", RMSE_PR_test)\n",
    "\n",
    "# Prediction with 10-Fold Cross Validation:\n",
    "y_pred_cv_PR = cross_val_predict(polynomial_reg, polynomial_features.fit_transform(X), y, cv=10)\n",
    "\n",
    "# Find accuracy after 10-Fold Cross Validation\n",
    "accuracy_cv_PR = r2_score(y, y_pred_cv_PR)\n",
    "print(\"Accuracy for 10-Fold Cross Predicted Polynomial Regression Model: \", accuracy_cv_PR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction with training dataset:\n",
    "y_pred_DTR_train = decision_tree_reg.predict(X_train)\n",
    "\n",
    "# Prediction with testing dataset:\n",
    "y_pred_DTR_test = decision_tree_reg.predict(X_test)\n",
    "\n",
    "# Find training accuracy for this model:\n",
    "accuracy_DTR_train = r2_score(y_train, y_pred_DTR_train)\n",
    "print(\"Training Accuracy for Decision Tree Regression Model: \", accuracy_DTR_train)\n",
    "\n",
    "# Find testing accuracy for this model:\n",
    "accuracy_DTR_test = r2_score(y_test, y_pred_DTR_test)\n",
    "print(\"Testing Accuracy for Decision Tree Regression Model: \", accuracy_DTR_test)\n",
    "\n",
    "# Find RMSE for training data:\n",
    "RMSE_DTR_train = sqrt(mean_squared_error(y_train, y_pred_DTR_train))\n",
    "print(\"RMSE for Training Data: \", RMSE_DTR_train)\n",
    "\n",
    "# Find RMSE for testing data:\n",
    "RMSE_DTR_test = sqrt(mean_squared_error(y_test, y_pred_DTR_test))\n",
    "print(\"RMSE for Testing Data: \", RMSE_DTR_test)\n",
    "\n",
    "# Prediction with 10-Fold Cross Validation:\n",
    "y_pred_cv_DTR = cross_val_predict(decision_tree_reg, X, y, cv=10)\n",
    "\n",
    "# Find accuracy after 10-Fold Cross Validation\n",
    "accuracy_cv_DTR = r2_score(y, y_pred_cv_DTR)\n",
    "print(\"Accuracy for 10-Fold Cross Predicted Decision Tree Regression Model: \", accuracy_cv_DTR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction with training dataset:\n",
    "y_pred_RFR_train = random_forest_reg.predict(X_train)\n",
    "\n",
    "# Prediction with testing dataset:\n",
    "y_pred_RFR_test = random_forest_reg.predict(X_test)\n",
    "\n",
    "# Find training accuracy for this model:\n",
    "accuracy_RFR_train = r2_score(y_train, y_pred_RFR_train)\n",
    "print(\"Training Accuracy for Random Forest Regression Model: \", accuracy_RFR_train)\n",
    "\n",
    "# Find testing accuracy for this model:\n",
    "accuracy_RFR_test = r2_score(y_test, y_pred_RFR_test)\n",
    "print(\"Testing Accuracy for Random Forest Regression Model: \", accuracy_RFR_test)\n",
    "\n",
    "# Find RMSE for training data:\n",
    "RMSE_RFR_train = sqrt(mean_squared_error(y_train, y_pred_RFR_train))\n",
    "print(\"RMSE for Training Data: \", RMSE_RFR_train)\n",
    "\n",
    "# Find RMSE for testing data:\n",
    "RMSE_RFR_test = sqrt(mean_squared_error(y_test, y_pred_RFR_test))\n",
    "print(\"RMSE for Testing Data: \", RMSE_RFR_test)\n",
    "\n",
    "# Prediction with 10-Fold Cross Validation:\n",
    "y_pred_cv_RFR = cross_val_predict(random_forest_reg, X, y, cv=10)\n",
    "\n",
    "# Find accuracy after 10-Fold Cross Validation\n",
    "accuracy_cv_RFR = r2_score(y, y_pred_cv_RFR)\n",
    "print(\"Accuracy for 10-Fold Cross Predicted Random Forest Regression Model: \", accuracy_cv_RFR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction with training dataset:\n",
    "y_pred_SVR_train = support_vector_reg.predict(X_train)\n",
    "\n",
    "# Prediction with testing dataset:\n",
    "y_pred_SVR_test = support_vector_reg.predict(X_test)\n",
    "\n",
    "# Find training accuracy for this model:\n",
    "accuracy_SVR_train = r2_score(y_train, y_pred_SVR_train)\n",
    "print(\"Training Accuracy for Support Vector Regression Model: \", accuracy_SVR_train)\n",
    "\n",
    "# Find testing accuracy for this model:\n",
    "accuracy_SVR_test = r2_score(y_test, y_pred_SVR_test)\n",
    "print(\"Testing Accuracy for Support Vector Regression Model: \", accuracy_SVR_test)\n",
    "\n",
    "# Find RMSE for training data:\n",
    "RMSE_SVR_train = sqrt(mean_squared_error(y_train, y_pred_SVR_train))\n",
    "print(\"RMSE for Training Data: \", RMSE_SVR_train)\n",
    "\n",
    "# Find RMSE for testing data:\n",
    "RMSE_SVR_test = sqrt(mean_squared_error(y_test, y_pred_SVR_test))\n",
    "print(\"RMSE for Testing Data: \", RMSE_SVR_test)\n",
    "\n",
    "# Prediction with 10-Fold Cross Validation:\n",
    "y_pred_cv_SVR = cross_val_predict(support_vector_reg, X, y, cv=10)\n",
    "\n",
    "# Find accuracy after 10-Fold Cross Validation\n",
    "accuracy_cv_SVR = r2_score(y, y_pred_cv_SVR)\n",
    "print(\"Accuracy for 10-Fold Cross Predicted Support Vector Regression Model: \", accuracy_cv_SVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all results in one table\n",
    "training_accuracies = [accuracy_MLR_train, accuracy_PR_train, accuracy_DTR_train, accuracy_RFR_train, accuracy_SVR_train]\n",
    "testing_accuracies = [accuracy_MLR_test, accuracy_PR_test, accuracy_DTR_test, accuracy_RFR_test, accuracy_SVR_test]\n",
    "training_RMSE = [RMSE_MLR_train, RMSE_PR_train, RMSE_DTR_train, RMSE_RFR_train, RMSE_SVR_train]\n",
    "testing_RMSE = [RMSE_MLR_test, RMSE_PR_test, RMSE_DTR_test, RMSE_RFR_test, RMSE_SVR_test]\n",
    "cv_accuracies = [accuracy_cv_MLR, accuracy_cv_PR, accuracy_cv_DTR, accuracy_cv_RFR, accuracy_cv_SVR]\n",
    "\n",
    "parameters = [\"fit_intercept=False\", \"fit_intercept=False\", \"max_depth=5\", \"n_estimators=400, max_depth=5\", \"kernel=”linear”, C=1000\"]\n",
    "\n",
    "table_data = {\"Parameters\": parameters, \"Training Accuracy\": training_accuracies, \"Testing Accuracy\": testing_accuracies, \n",
    "              \"Training RMSE\": training_RMSE, \"Testing RMSE\": testing_RMSE, \"10-Fold Score\": cv_accuracies}\n",
    "model_names = [\"Multiple Linear Regression\", \"Polynomial Regression\", \"Decision Tree Regression\", \"Random Forest Regression\", \"Support Vector Regression\"]\n",
    "\n",
    "table_dataframe = pd.DataFrame(data=table_data, index=model_names)\n",
    "table_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
